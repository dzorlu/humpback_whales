{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import create_model_fn\n",
    "from data.triplet_generator import TripletGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "NB_CLASSES_META_LEARNING = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_file_path='/data/whales/train.csv'\n",
    "_image_train_path='/data/whales/train'\n",
    "_image_test_path='/data/whales/test'\n",
    "#\n",
    "_file_path='/Users/deniz/Documents/whales/train.csv'\n",
    "_image_train_path='/Users/deniz/Documents/whales/train'\n",
    "_image_test_path='/Users/deniz/Documents/whales/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size', None), ('dropout', 0.3), ('embedding_hidden_dim', 64), ('file_path', '/Users/deniz/Documents/whales/train.csv'), ('fit', True), ('image_dim', (224, 224, 3)), ('image_test_path', '/Users/deniz/Documents/whales/test'), ('image_train_path', '/Users/deniz/Documents/whales/train'), ('loss', None), ('lr_policy', None), ('lr_rate', 0.02), ('model_architecture', 'convnet'), ('nb_classes', 10), ('nb_epochs', None), ('nb_layers_to_freeze', 0), ('pretrained', True), ('tmp_data_path', '/tmp/whales/'), ('triplet_margin', None)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = tf.contrib.training.HParams(\n",
    "    fit=True,\n",
    "    file_path=_file_path,\n",
    "    image_train_path=_image_train_path,\n",
    "    image_test_path=_image_test_path,\n",
    "    model_architecture='convnet',\n",
    "    tmp_data_path=\"/tmp/whales/\",\n",
    "    batch_size=None,\n",
    "    nb_epochs=None,\n",
    "    lr_rate=0.02,\n",
    "    lr_policy=None,\n",
    "    pretrained=True,\n",
    "    nb_layers_to_freeze=0,\n",
    "    loss=None,\n",
    "    embedding_hidden_dim=64,\n",
    "    triplet_margin=None,\n",
    "    nb_classes=10,\n",
    "    dropout=0.3)\n",
    "model_params.add_hparam('image_dim', (224, 224, 3))\n",
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model.model:pretrained..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
      "Tensor(\"conv0_relu/Relu6:0\", shape=(?, 111, 111, 64), dtype=float32)\n",
      "Tensor(\"conv1_relu/Relu6:0\", shape=(?, 55, 55, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model.model:append the top to the structure..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2_relu/Relu6:0\", shape=(?, 27, 27, 64), dtype=float32)\n",
      "Tensor(\"conv3_relu/Relu6:0\", shape=(?, 13, 13, 64), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 111, 111, 64)      1728      \n",
      "_________________________________________________________________\n",
      "conv0_bn (BatchNormalization (None, 111, 111, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv0_relu (ReLU)            (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 55, 55, 64)        36864     \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 27, 27, 64)        36864     \n",
      "_________________________________________________________________\n",
      "conv2_bn (BatchNormalization (None, 27, 27, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2_relu (ReLU)            (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 13, 13, 64)        36864     \n",
      "_________________________________________________________________\n",
      "conv3_bn (BatchNormalization (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv3_relu (ReLU)            (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 6, 6, 64)          36864     \n",
      "_________________________________________________________________\n",
      "conv4_bn (BatchNormalization (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv4_relu (ReLU)            (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 10)          650       \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 151,114\n",
      "Trainable params: 150,474\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:None\n"
     ]
    }
   ],
   "source": [
    "model = create_model_fn(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    'featurewise_center': False,\n",
    "    'featurewise_std_normalization': False,\n",
    "    'rotation_range': 20,\n",
    "    'width_shift_range': 0.1,\n",
    "    'height_shift_range': 0.1,\n",
    "    'zoom_range': 0.2,\n",
    "    'shear_range': 0.4,\n",
    "   }\n",
    "NB_CLASSES_META_LEARNING = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.triplet_generator:exclude_class: ['new_whale']\n",
      "INFO:data.triplet_generator:class_weight_type: None\n",
      "INFO:data.triplet_generator:9664 instances excluded\n",
      "INFO:data.triplet_generator:data has shape: (12415, 2)\n",
      "INFO:data.triplet_generator:{'featurewise_center': False, 'featurewise_std_normalization': False, 'rotation_range': 20, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'zoom_range': 0.2, 'shear_range': 0.4, 'preprocessing_function': <function _preprocess_input at 0x12d825488>}\n",
      "INFO:data.triplet_generator:exclude_class: ['new_whale']\n",
      "INFO:data.triplet_generator:class_weight_type: None\n",
      "INFO:data.triplet_generator:9664 instances excluded\n",
      "INFO:data.triplet_generator:data has shape: (3282, 2)\n",
      "INFO:data.triplet_generator:{'featurewise_center': False, 'featurewise_std_normalization': False, 'rotation_range': 20, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'zoom_range': 0.2, 'shear_range': 0.4, 'preprocessing_function': <function _preprocess_input at 0x12d825488>}\n"
     ]
    }
   ],
   "source": [
    "train_generator = TripletGenerator(file_path=model_params.file_path,\n",
    "                                   image_path=model_params.image_train_path,\n",
    "                                   image_test_path=model_params.image_test_path,\n",
    "                                   nb_classes_batch=NB_CLASSES_META_LEARNING,\n",
    "                                   nb_images_per_class_batch=5,\n",
    "                                   validation_split=0.2,\n",
    "                                   subset='training',\n",
    "                                   **data_params)\n",
    "eval_generator = TripletGenerator(file_path=model_params.file_path,\n",
    "                                  image_path=model_params.image_train_path,\n",
    "                                  image_test_path=model_params.image_test_path,\n",
    "                                  nb_classes_batch=NB_CLASSES_META_LEARNING,\n",
    "                                  nb_images_per_class_batch=5,\n",
    "                                  validation_split=0.2,\n",
    "                                  subset='eval',\n",
    "                                  **data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator), len(eval_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_params, train_generator, eval_generator, outer_step_size = 0.02, steps=5):\n",
    "    def fn(_gen):\n",
    "        for a, b in _gen:\n",
    "            yield a, b\n",
    "    nb_steps_per_epoch = len(train_generator)\n",
    "    nb_steps_per_epoch_val = len(eval_generator)\n",
    "    _generator = fn(train_generator)\n",
    "    _eval_generator = fn(eval_generator)\n",
    "    NB_EPOCHS = 10\n",
    "    # reptile training loop\n",
    "    for i in range(NB_EPOCHS):\n",
    "        for _ in range(nb_steps_per_epoch):\n",
    "            \n",
    "            weights_before = model.weights\n",
    "            \n",
    "            # sample a new task. need to take k steps.\n",
    "            x, y = next(_generator)\n",
    "            # randomize bc generator does not\n",
    "            ix = list(range(x.shape[0]))\n",
    "            np.random.shuffle(ix)\n",
    "            x, y = x[ix], y[ix]\n",
    "\n",
    "            batch_size = x.shape[0] // steps\n",
    "            # take k steps\n",
    "            for s in range(steps):   \n",
    "                _x, _y = x[s * batch_size: (s+1) * batch_size,:,:,:], y[s * batch_size: (s+1) * batch_size,:]\n",
    "                model.train_on_batch(_x, _y)\n",
    "            weights_after = model.weights\n",
    "            \n",
    "            # meta update after task training.\n",
    "            for w_ix in range(len(weights_before)):\n",
    "                model.weights[i] = (weights_before[i] +\n",
    "                                    (weights_after[i] - weights_before[i]) * outer_step_size)\n",
    "            \n",
    "        #eval\n",
    "        print('eval')\n",
    "        outs_per_batch = []\n",
    "        for s in range(nb_steps_per_epoch_val):\n",
    "            x, y = next(_eval_generator)\n",
    "            outs = model.test_on_batch(x, y)\n",
    "            outs_per_batch.append(outs)\n",
    "        averages = []\n",
    "        # outs: (val_loss, accuracy, top_5_accuracy)\n",
    "        stateful_metric_indices = [1,2]\n",
    "        for i in range(len(outs)):\n",
    "            if i not in stateful_metric_indices:\n",
    "                averages.append(np.average([out[i] for out in outs_per_batch]))\n",
    "            else:\n",
    "                # error on the last batch.\n",
    "                averages.append(np.float64(outs_per_batch[-1][i]))\n",
    "        print(\"epoch: {}, metrics: {}\".format(i, averages))\n",
    "        \n",
    "    #TODO: eval metric. early stopping based on that.\n",
    "    model.save(model_params.tmp_data_path + 'meta_learning_model.h5')\n",
    "    return model, averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-554b49641a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-86af5dd29fbc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_params, train_generator, eval_generator, outer_step_size, steps)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mweights_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, all_outs = train(model_params, train_generator, eval_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nn_preds():\n",
    "    x, img_names = generator.get_test_images_and_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test time.\n",
    "def test(model_params, nn_classifier_predictions, nb_classes_meta=NB_CLASSES_META_LEARNING):\n",
    "    \"\"\"\n",
    "    nn_classifier_predictions: [test_data_len, nb_classes]\n",
    "    \"\"\"\n",
    "    # test images and names\n",
    "    gen = Generator(file_path=model_params.file_path,\n",
    "                    image_path=model_params.image_train_path,\n",
    "                    image_test_path=model_params.image_test_path,\n",
    "                    batch_size=model_params.batch_size)\n",
    "    x, img_names = generator.get_test_images_and_names()\n",
    "    nn_classifier_predictions_class_ix = np.argsort(-nn_classifier_predictions)[:nb_classes_meta]\n",
    "    assert len(x), len(nn_classifier_predictions_class_ix)\n",
    "    # load the meta-training model\n",
    "    model = load_model(model_params.tmp_data_path + 'meta_learning_model.h5')\n",
    "    \n",
    "    # each prediction becomes a task downstream\n",
    "    ensemble_preds = []\n",
    "    for i,task_class_ids in enumerate(nn_classifier_predictions_class_ix):\n",
    "        weights_before = model.weights\n",
    "        # training - training images\n",
    "        batch_x, batch_y = test_generator.get_train_image_from_class_ix(task_class_ids)\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "        # predict - test image\n",
    "        outs = model.predict_on_batch(x[i])\n",
    "        # take top 5 predictions\n",
    "        pred_class_ix = np.argmax(-outs)[:5]\n",
    "        ensemble_preds.append(pred_class_ix)\n",
    "        # revert back for the next task\n",
    "        model.weights = weights_before\n",
    "    return np.vstack(ensemble_preds)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30285652 0.80148075]\n",
      "[0.07503177 0.27112158]\n",
      "[0.14037516 0.54531099]\n",
      "[0.10841571 0.93512427]\n",
      "[0.11505544 0.24019544]\n",
      "[0.76894898 0.39560027]\n",
      "[0.86139979 0.17824399]\n",
      "[0.81073242 0.93174129]\n",
      "[0.82807975 0.89988127]\n",
      "[0.79756544 0.58660252]\n"
     ]
    }
   ],
   "source": [
    "arr= np.random.random([10,2])\n",
    "for a in arr:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.triplet_generator:exclude_class: ['new_whale']\n",
      "INFO:data.triplet_generator:class_weight_type: None\n",
      "INFO:data.triplet_generator:9664 instances excluded\n",
      "INFO:data.triplet_generator:data has shape: (15697, 2)\n",
      "INFO:data.triplet_generator:{'preprocessing_function': <function _preprocess_input at 0x12f200400>}\n"
     ]
    }
   ],
   "source": [
    "test_generator = TripletGenerator(file_path=model_params.file_path,\n",
    "                                   image_path=model_params.image_train_path,\n",
    "                                   image_test_path=model_params.image_test_path,\n",
    "                                   nb_classes_batch=NB_CLASSES_META_LEARNING,\n",
    "                                   shuffle=False,\n",
    "                                   nb_images_per_class_batch=1, # test is one-shot learning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = test_generator.get_image_from_class_ix([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3tf",
   "language": "python",
   "name": "py3tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
