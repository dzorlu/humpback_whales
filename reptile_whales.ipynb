{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import create_model_fn\n",
    "from data.triplet_generator import TripletGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParams([('batch_size', None), ('dropout', 0.3), ('embedding_hidden_dim', 64), ('file_path', '/Users/deniz/Documents/whales/train.csv'), ('fit', True), ('image_dim', (224, 224, 3)), ('image_test_path', '/Users/deniz/Documents/whales/test'), ('image_train_path', '/Users/deniz/Documents/whales/train'), ('loss', None), ('lr_policy', None), ('lr_rate', 0.02), ('model_architecture', 'convnet'), ('nb_classes', 10), ('nb_epochs', None), ('nb_layers_to_freeze', 0), ('pretrained', True), ('tmp_data_path', '/tmp/whales/'), ('triplet_margin', None)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = tf.contrib.training.HParams(\n",
    "    fit=True,\n",
    "    file_path='/Users/deniz/Documents/whales/train.csv',\n",
    "    image_train_path='/Users/deniz/Documents/whales/train',\n",
    "    image_test_path='/Users/deniz/Documents/whales/test',\n",
    "    model_architecture='convnet',\n",
    "    tmp_data_path=\"/tmp/whales/\",\n",
    "    batch_size=None,\n",
    "    nb_epochs=None,\n",
    "    lr_rate=0.02,\n",
    "    lr_policy=None,\n",
    "    pretrained=True,\n",
    "    nb_layers_to_freeze=0,\n",
    "    loss=None,\n",
    "    embedding_hidden_dim=64,\n",
    "    triplet_margin=None,\n",
    "    nb_classes=10,\n",
    "    dropout=0.3)\n",
    "model_params.add_hparam('image_dim', (224, 224, 3))\n",
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model.model:pretrained..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_2:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
      "Tensor(\"conv0_relu_1/Relu6:0\", shape=(?, 111, 111, 64), dtype=float32)\n",
      "Tensor(\"conv1_relu_1/Relu6:0\", shape=(?, 55, 55, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model.model:append the top to the structure..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2_relu_1/Relu6:0\", shape=(?, 27, 27, 64), dtype=float32)\n",
      "Tensor(\"conv3_relu_1/Relu6:0\", shape=(?, 13, 13, 64), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 111, 111, 64)      1728      \n",
      "_________________________________________________________________\n",
      "conv0_bn (BatchNormalization (None, 111, 111, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv0_relu (ReLU)            (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 55, 55, 64)        36864     \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 55, 55, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 27, 27, 64)        36864     \n",
      "_________________________________________________________________\n",
      "conv2_bn (BatchNormalization (None, 27, 27, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2_relu (ReLU)            (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 13, 13, 64)        36864     \n",
      "_________________________________________________________________\n",
      "conv3_bn (BatchNormalization (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv3_relu (ReLU)            (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 6, 6, 64)          36864     \n",
      "_________________________________________________________________\n",
      "conv4_bn (BatchNormalization (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv4_relu (ReLU)            (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 10)          650       \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 151,114\n",
      "Trainable params: 150,474\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:None\n"
     ]
    }
   ],
   "source": [
    "model = create_model_fn(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    'featurewise_center': False,\n",
    "    'featurewise_std_normalization': False,\n",
    "    'rotation_range': 20,\n",
    "    'width_shift_range': 0.1,\n",
    "    'height_shift_range': 0.1,\n",
    "    'zoom_range': 0.2,\n",
    "    'shear_range': 0.4,\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.triplet_generator:exclude_class: ['new_whale']\n",
      "INFO:data.triplet_generator:class_weight_type: None\n",
      "INFO:data.triplet_generator:9664 instances excluded\n",
      "INFO:data.triplet_generator:data has shape: (12415, 2)\n",
      "INFO:data.triplet_generator:{'featurewise_center': False, 'featurewise_std_normalization': False, 'rotation_range': 20, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'zoom_range': 0.2, 'shear_range': 0.4, 'preprocessing_function': <function _preprocess_input at 0x129fcb488>}\n",
      "INFO:data.triplet_generator:exclude_class: ['new_whale']\n",
      "INFO:data.triplet_generator:class_weight_type: None\n",
      "INFO:data.triplet_generator:9664 instances excluded\n",
      "INFO:data.triplet_generator:data has shape: (3282, 2)\n",
      "INFO:data.triplet_generator:{'featurewise_center': False, 'featurewise_std_normalization': False, 'rotation_range': 20, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'zoom_range': 0.2, 'shear_range': 0.4, 'preprocessing_function': <function _preprocess_input at 0x129fcb488>}\n"
     ]
    }
   ],
   "source": [
    "train_generator = TripletGenerator(file_path=model_params.file_path,\n",
    "                                   image_path=model_params.image_train_path,\n",
    "                                   image_test_path=model_params.image_test_path,\n",
    "                                   nb_classes_batch=10,\n",
    "                                   nb_images_per_class_batch=5,\n",
    "                                   validation_split=0.2,\n",
    "                                   subset='training',\n",
    "                                   **data_params)\n",
    "eval_generator = TripletGenerator(file_path=model_params.file_path,\n",
    "                                  image_path=model_params.image_train_path,\n",
    "                                  image_test_path=model_params.image_test_path,\n",
    "                                  nb_classes_batch=10,\n",
    "                                  nb_images_per_class_batch=5,\n",
    "                                  validation_split=0.2,\n",
    "                                  subset='eval',\n",
    "                                  **data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator), len(eval_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_generator, eval_generator,outer_step_size = 0.02, steps=5):\n",
    "    def fn(_gen):\n",
    "        for a, b in _gen:\n",
    "            yield a, b\n",
    "    nb_steps_per_epoch = len(train_generator)\n",
    "    nb_steps_per_epoch_val = len(eval_generator)\n",
    "    generator = fn(train_generator)\n",
    "    eval_generator = fn(eval_generator)\n",
    "    NB_EPOCHS = 1\n",
    "    # reptile training loop\n",
    "    for i in range(NB_EPOCHS):\n",
    "        for s in range(nb_steps_per_epoch):\n",
    "            \n",
    "            weights_before = model.weights\n",
    "            # sample a new task. need to take k steps.\n",
    "            x, y = next(generator)\n",
    "            # randomize bc generator does not\n",
    "            ix = list(range(x.shape[0]))\n",
    "            np.random.shuffle(ix)\n",
    "            x, y = x[ix], y[ix]\n",
    "\n",
    "            batch_size = x.shape[0] // steps\n",
    "            for s in range(steps):   \n",
    "                _x, _y = x[s * batch_size: (s+1) * batch_size,:,:,:], y[s * batch_size: (s+1) * batch_size,:]\n",
    "                model.train_on_batch(_x, _y)\n",
    "            weights_after = model.weights\n",
    "            # meta update after task.\n",
    "            for w_ix in range(len(weights_before)):\n",
    "                model.weights[i] = (weights_before[i] +\n",
    "                                    (weights_after[i] - weights_before[i]) * outer_step_size)\n",
    "            \n",
    "        # eval\n",
    "        print('eval')\n",
    "        for s in range(nb_steps_per_epoch_val):\n",
    "            outs = model.test_on_batch(x, y)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(train_generator, eval_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3tf",
   "language": "python",
   "name": "py3tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
